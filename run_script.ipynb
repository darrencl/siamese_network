{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "\n",
    "\"\"\"\n",
    "Split the dataset so that training occurs on digits [2,3,4,5,6,7] and testing occurs accross all digits\n",
    "\"\"\"\n",
    "def split_dataset(x_tr,y_tr,x_t,y_t): # Split dataset into training and test sets using given integers\n",
    "    # Combine datasets to be split based on integers\n",
    "    X = np.concatenate((x_tr,x_t))\n",
    "    Y = np.concatenate((y_tr,y_t))\n",
    "    \n",
    "    tr_ints , t_ints = [2,3,4,5,6,7], [0,1,8,9]\n",
    "    \n",
    "    # Creates a boolean mask for each set\n",
    "    tr_set = [ x in tr_ints for x in Y ]\n",
    "    t_set = [ x in t_ints for x in Y ]\n",
    "    \n",
    "    x_tr, x_t = X[tr_set], X[t_set]\n",
    "    y_tr, y_t = Y[tr_set], Y[t_set]\n",
    "\n",
    "    # Split 80% to training and 20% to test\n",
    "    split = int(len(x_tr) * 0.8)    \n",
    "    x_t2, x_tr = x_tr[split::], x_tr[:split:]\n",
    "    y_t2, y_tr = y_tr[split::], y_tr[:split:]\n",
    "\n",
    "    return ((x_tr, x_t, x_t2)), ((y_tr, y_t, y_t2))\n",
    "\"\"\"\n",
    "Create pairs from dataset that alternate between positive and negative\n",
    "\"\"\"\n",
    "def create_pairs(xlist, digit_idx):\n",
    "    #Initialise lists\n",
    "    pairs = []\n",
    "    labels = []\n",
    "    \n",
    "    digits = [d for d in range(num_classes) if len(digit_idx[d] > 0)]\n",
    "    digit_len = [len(digit_idx[d]) for d in digits] # Get the number of items for each digit/class\n",
    "    \n",
    "    n = min(digit_len) - 1 # Find the length of the smallest set of digits\n",
    "    \n",
    "    for d in digits:\n",
    "        for i in range(n):\n",
    "            # Assign positive pair\n",
    "            pos_idx1, pos_idx2 = digit_idx[d][i], digit_idx[d][i+1]\n",
    "            pos1, pos2 = xlist[pos_idx1], xlist[pos_idx2]\n",
    "            pairs += [[pos1,pos2]]\n",
    "            \n",
    "            # Assign a random digit that is not the original digit\n",
    "            other = [dgt for dgt in digits if dgt != d]\n",
    "            rand_d = int(np.random.choice(digits, 1, replace = False))\n",
    "            \n",
    "            # Assign negative pair\n",
    "            neg_idx1, neg_idx2 = digit_idx[d][i], digit_idx[rand_d][i]\n",
    "            neg1, neg2 = xlist[neg_idx1], xlist[neg_idx2]\n",
    "            pairs += [[neg1,neg2]]\n",
    "            \n",
    "            # Assign labels for positive and negative pair\n",
    "            labels += [1,0]\n",
    "            \n",
    "    return np.array(pairs), np.array(labels)\n",
    "\n",
    "\"\"\"\n",
    "Create the base model for siamese network, this is based on CNN architecture\n",
    "\"\"\"\n",
    "def base_model(input_shape):\n",
    "    input_layer = keras.layers.Input(shape=input_shape)\n",
    "    model = keras.layers.Conv2D(32, kernel_size=(3, 3),\n",
    "                     activation='relu')(input_layer)\n",
    "    model = keras.layers.Conv2D(64, (3, 3), activation='relu')(model)\n",
    "    model = keras.layers.MaxPooling2D(pool_size=(2, 2))(model)\n",
    "    model = keras.layers.Dropout(0.25)(model)\n",
    "    model = keras.layers.Flatten()(model)\n",
    "    model = keras.layers.Dense(128, activation='relu')(model)\n",
    "    model = keras.layers.Dropout(0.5)(model)\n",
    "    model = keras.layers.Dense(num_classes, activation='softmax')(model)\n",
    "\n",
    "    return Model(input_layer, model)\n",
    "\n",
    "\"\"\"\n",
    "Define functions to compute euclidean distance.\n",
    "The eucledian distance can be computed by square all the distance between x and y, then square it (power of 2). \n",
    "Lastly, the distance is the squareroot of the sum all of results. \n",
    ":param: 2D vector\n",
    ":return enclidean distance\n",
    "\"\"\"\n",
    "def euclidean_distance(vec_2d):\n",
    "    x, y = vec_2d\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    result = K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "    return result\n",
    "\n",
    "\"\"\"\n",
    "Define functions to convert the shape of euclidean distance function.\n",
    "This will be used in to define the output_shape of the Lambda layer\n",
    ":params: shapes (2D/x and y)\n",
    ":return: tuples(x,1)\n",
    "\"\"\"\n",
    "def euclidean_distance_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "\"\"\"\n",
    "Generate accuracy for siamese net.\n",
    "The threshold is set to 0.5, if the distance predicted is more than threshold, it will be counted as 0 (= False).\n",
    "In other words, if the distance between pair is close enough, it will be consider them as identical pair.\n",
    "Finally the prediction is compared to the ground truth\n",
    ":params y_ground_truth: ground truth of the data\n",
    ":params y_pred: prediction result from the model\n",
    ":return: accuracy (since the data are either 0 or 1 (true or false), we can use mean function of comparison to compute accuracy)\n",
    "\"\"\"\n",
    "def compute_accuracy(y_ground_truth, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    pred = y_pred.ravel() < 0.5\n",
    "    return np.mean(pred == y_ground_truth)\n",
    "\n",
    "\n",
    "def contrastive_loss(y_true, y_pred):\n",
    "    '''Contrastive loss from Hadsell-et-al.'06\n",
    "    http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf\n",
    "    '''\n",
    "    margin = 1\n",
    "    sqaure_pred = K.square(y_pred)\n",
    "    margin_square = K.square(K.maximum(margin - y_pred, 0))\n",
    "    return K.mean(y_true * sqaure_pred + (1 - y_true) * margin_square)\n",
    "\"\"\"\n",
    "Main code start \n",
    "\"\"\"\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "\"\"\"\n",
    "1. Get input size to be used later in defining Sequencial model\n",
    "\"\"\"\n",
    "# Define image dimension (rows and cols) and number of classes\n",
    "img_rows, img_cols = 28, 28\n",
    "num_classes = 10\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "left_input = keras.layers.Input(shape=input_shape)\n",
    "right_input = keras.layers.Input(shape=input_shape)\n",
    "\"\"\"\n",
    "2. Preprocess dataset\n",
    "\"\"\"\n",
    "# Split dataset\n",
    "x_set, y_set = split_dataset(x_train, y_train, x_test, y_test)\n",
    "x_train, x_test, x_test_unknown = x_set\n",
    "y_train, y_test, y_test_unknown = y_set\n",
    "\n",
    "# Create training pairs\n",
    "digit_idx = [np.where(y_train == i)[0] for i in range(num_classes)]\n",
    "siamese_train_pairs, siamese_train_y = create_pairs(x_train, digit_idx)\n",
    "\n",
    "# Create test pairs\n",
    "digit_idx = [np.where(y_test == i)[0] for i in range(num_classes)]\n",
    "siamese_test_pairs, siamese_test_y = create_pairs(x_test, digit_idx)\n",
    "\n",
    "# Create unknown test pairs\n",
    "digit_idx = [np.where(y_test_unknown == i)[0] for i in range(num_classes)]\n",
    "siamese_test_unknown_pairs, siamese_test_unknown_y = create_pairs(x_test_unknown, digit_idx)\n",
    "\n",
    "\"\"\"\n",
    "3. Create CNN Architecture\n",
    "\"\"\"\n",
    "model = base_model(input_shape=input_shape)\n",
    "\"\"\"\n",
    "4. Siamese network\n",
    "\"\"\"\n",
    "# Processed left and right inputs using the model\n",
    "processed_l = model(left_input)\n",
    "processed_r = model(right_input)\n",
    "\n",
    "# Merge them using distance function\n",
    "# The distance function used is L2 distance (also be called Euclidean distance)\n",
    "# To do this, Lambda layer is needed to wrap the distance function (writtein in lambda function) in to layer object \n",
    "distance = keras.layers.Lambda(euclidean_distance,\n",
    "                  output_shape=euclidean_distance_output_shape)([processed_l, processed_r])\n",
    "\n",
    "# Create siamese net\n",
    "siamese_model = Model([left_input, right_input], distance)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "33536/60720 [===============>..............] - ETA: 1:26 - loss: 0.5136 - accuracy: 0.4983"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-3d16ee70e24b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m siamese_model.fit([siamese_train_pairs[:, 0], siamese_train_pairs[:, 1]], siamese_train_y,\n\u001b[0;32m     12\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                 epochs=epochs)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1039\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2713\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2714\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2715\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2716\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2717\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2674\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2675\u001b[1;33m             \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2676\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1398\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1400\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "5. Train the model using pairs of data\n",
    "\"\"\"\n",
    "# Specify number of epochs for training\n",
    "epochs = 10\n",
    "\n",
    "siamese_model.compile(loss=contrastive_loss,\n",
    "                    optimizer=keras.optimizers.Adam(),\n",
    "                    metrics=[accuracy])\n",
    "\n",
    "siamese_model.fit([siamese_train_pairs[:, 0], siamese_train_pairs[:, 1]], siamese_train_y,\n",
    "                batch_size=128,\n",
    "                epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "6. Get train and test set\n",
    "\"\"\"\n",
    "\n",
    "train_y_pred = siamese_model.predict([siamese_train_pairs[:, 0], siamese_train_pairs[:, 1]])\n",
    "train_accuracy = compute_accuracy(y_ground_truth=siamese_train_y, y_pred=train_y_pred)\n",
    "\n",
    "test_y_pred = siamese_model.predict([siamese_test_pairs[:, 0], siamese_test_pairs[:, 1]])\n",
    "test_accuracy = compute_accuracy(y_ground_truth=siamese_test_y, y_pred=test_y_pred)\n",
    "\n",
    "test_unknown_y_pred = siamese_model.predict([siamese_test_unknown_pairs[:, 0], siamese_test_unknown_pairs[:, 1]])\n",
    "test_unknown_accuracy = compute_accuracy(y_ground_truth=siamese_test_unknown_y, y_pred=test_unknown_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('======Siamese Network Result======')\n",
    "print(f'Train accuracy: {train_accuracy}')\n",
    "print(f'Test accuracy: {test_accuracy}')\n",
    "print(f'Test unknown accuracy: {test_unknown_accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    '''Compute classification accuracy with a fixed threshold on distances.\n",
    "    '''\n",
    "    return K.mean(K.equal(y_true, K.cast(y_pred < 0.5, y_true.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_set[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for pair, y in zip(siamese_train_pairs[1::6000], siamese_train_y[1::6000]):\n",
    "    \n",
    "    plt.imshow(pair[0].reshape((28,28)), cmap='gray')\n",
    "    plt.show()\n",
    "    plt.imshow(pair[1].reshape((28,28)), cmap='gray')\n",
    "    plt.show()\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_train_pairs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
